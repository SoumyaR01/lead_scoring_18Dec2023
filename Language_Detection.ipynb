{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOJY+hh+rahV/jjY5xIVeFI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SoumyaR01/lead_scoring_18Dec2023/blob/main/Language_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install git+https://github.com/speechbrain/speechbrain.git@develop"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KZkBiTxDqE5v",
        "outputId": "5fef583e-feaa-437c-e7ac-77398d4743af"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/speechbrain/speechbrain.git@develop\n",
            "  Cloning https://github.com/speechbrain/speechbrain.git (to revision develop) to /tmp/pip-req-build-bjc9zs6z\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/speechbrain/speechbrain.git /tmp/pip-req-build-bjc9zs6z\n",
            "  Resolved https://github.com/speechbrain/speechbrain.git to commit b18646d80c7d5081a99a32f2a3e44cebe2a8249f\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting hyperpyyaml (from speechbrain==1.0.2)\n",
            "  Downloading HyperPyYAML-1.2.2-py3-none-any.whl.metadata (7.6 kB)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from speechbrain==1.0.2) (1.4.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from speechbrain==1.0.2) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from speechbrain==1.0.2) (24.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from speechbrain==1.0.2) (1.13.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from speechbrain==1.0.2) (0.2.0)\n",
            "Requirement already satisfied: torch>=1.9 in /usr/local/lib/python3.10/dist-packages (from speechbrain==1.0.2) (2.5.1+cu121)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (from speechbrain==1.0.2) (2.5.1+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from speechbrain==1.0.2) (4.67.1)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (from speechbrain==1.0.2) (0.27.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->speechbrain==1.0.2) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->speechbrain==1.0.2) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->speechbrain==1.0.2) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->speechbrain==1.0.2) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->speechbrain==1.0.2) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->speechbrain==1.0.2) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.9->speechbrain==1.0.2) (1.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->speechbrain==1.0.2) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->speechbrain==1.0.2) (2.32.3)\n",
            "Collecting ruamel.yaml>=0.17.28 (from hyperpyyaml->speechbrain==1.0.2)\n",
            "  Downloading ruamel.yaml-0.18.7-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting ruamel.yaml.clib>=0.2.7 (from ruamel.yaml>=0.17.28->hyperpyyaml->speechbrain==1.0.2)\n",
            "  Downloading ruamel.yaml.clib-0.2.12-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.9->speechbrain==1.0.2) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->speechbrain==1.0.2) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->speechbrain==1.0.2) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->speechbrain==1.0.2) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->speechbrain==1.0.2) (2024.12.14)\n",
            "Downloading HyperPyYAML-1.2.2-py3-none-any.whl (16 kB)\n",
            "Downloading ruamel.yaml-0.18.7-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.9/116.9 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ruamel.yaml.clib-0.2.12-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (722 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m722.2/722.2 kB\u001b[0m \u001b[31m36.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: speechbrain\n",
            "  Building wheel for speechbrain (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for speechbrain: filename=speechbrain-1.0.2-py3-none-any.whl size=844844 sha256=924cba63dfe1c3049cc9d00df7692eebafb82b8e170b3eebe6927c82fa0c8c22\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-06gwfxqv/wheels/e1/a5/ca/79fbb0a28f6f392850cfd5bac6a4dcec0f10a7e49d4c1e87cb\n",
            "Successfully built speechbrain\n",
            "Installing collected packages: ruamel.yaml.clib, ruamel.yaml, hyperpyyaml, speechbrain\n",
            "Successfully installed hyperpyyaml-1.2.2 ruamel.yaml-0.18.7 ruamel.yaml.clib-0.2.12 speechbrain-1.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(torch.cuda.is_available())  # Prints True if CUDA is available\n",
        "print(torch.cuda.device_count()) # Prints the number of CUDA-enabled GPUs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wJok_PLSq4Vd",
        "outputId": "b733796b-82b5-4bdf-be6c-25b0438f554f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z9D8UbIKrdPT",
        "outputId": "2f83acd8-90b8-4128-d7d5-09dbd2d85ff0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Jan  2 06:33:25 2025       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   60C    P8              10W /  70W |      3MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "o9wqhefBrhP-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "te3Ur3Y9tMp4",
        "outputId": "eceb7e76-86dd-46cd-d5d2-7d89b1b00b1c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.1+cu121)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (11.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(torch.cuda.is_available())\n",
        "if torch.cuda.is_available():\n",
        "    print(torch.cuda.get_device_name(0))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZUjb0Yemswt6",
        "outputId": "f7fd6667-aac8-463d-8705-a97e171d48af"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchaudio\n",
        "from speechbrain.inference.classifiers import EncoderClassifier\n",
        "import os\n",
        "import time"
      ],
      "metadata": {
        "id": "ArOQHwgiuy-b"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: convert mp3 to wav\n",
        "\n",
        "!pip install pydub\n",
        "\n",
        "from pydub import AudioSegment\n",
        "\n",
        "def convert_mp3_to_wav(input_file, output_file):\n",
        "    \"\"\"Converts an MP3 file to WAV format.\n",
        "\n",
        "    Args:\n",
        "        input_file: Path to the input MP3 file.\n",
        "        output_file: Path to the output WAV file.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        sound = AudioSegment.from_mp3(input_file)\n",
        "        sound.export(output_file, format=\"wav\")\n",
        "        print(f\"Successfully converted {input_file} to {output_file}\")\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: Input file '{input_file}' not found.\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "\n",
        "# Example usage\n",
        "# Replace 'input.mp3' and 'output.wav' with your actual file paths\n",
        "input_mp3_file = '/content/Sudha Murty Speech.mp3'\n",
        "output_wav_file = '/content/outputwav.wav'\n",
        "convert_mp3_to_wav(input_mp3_file, output_wav_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XR5l9J2lzgUE",
        "outputId": "9106abc8-709a-4c0b-ba61-9114bfbb3dd9"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (0.25.1)\n",
            "Successfully converted /content/Sudha Murty Speech.mp3 to /content/outputwav.wav\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-chl2TGpN05",
        "outputId": "55fe5de7-141b-4564-9240-9bc0180c204e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(tensor([[-2.9266e+01, -2.4988e+01, -2.6575e+01, -2.2365e+01, -5.8433e+00,\n",
            "         -2.6655e+01, -3.0108e+01, -2.5232e+01, -2.8422e+01, -2.9108e-03,\n",
            "         -2.7455e+01, -2.6004e+01, -2.4815e+01, -2.4079e+01, -2.5300e+01,\n",
            "         -2.3880e+01, -2.4394e+01, -2.5196e+01, -2.3488e+01, -2.0692e+01,\n",
            "         -2.4699e+01, -2.2420e+01, -2.6062e+01, -2.3627e+01, -2.6092e+01,\n",
            "         -2.1675e+01, -2.6345e+01, -2.6434e+01, -2.1391e+01, -2.1494e+01,\n",
            "         -2.8049e+01, -1.3759e+01, -3.2954e+01, -2.6627e+01, -2.7494e+01,\n",
            "         -1.3248e+01, -2.4684e+01, -2.1614e+01, -2.1818e+01, -1.5019e+01,\n",
            "         -2.6747e+01, -2.9885e+01, -2.5911e+01, -2.3761e+01, -2.5837e+01,\n",
            "         -2.2863e+01, -2.9398e+01, -1.7744e+01, -2.8417e+01, -2.9928e+01,\n",
            "         -1.8485e+01, -2.2452e+01, -2.5464e+01, -2.2089e+01, -2.1588e+01,\n",
            "         -3.0064e+01, -2.8822e+01, -2.8466e+01, -2.7403e+01, -2.6876e+01,\n",
            "         -1.9744e+01, -1.8015e+01, -2.6356e+01, -1.2516e+01, -2.3329e+01,\n",
            "         -2.1904e+01, -2.6809e+01, -1.4533e+01, -2.7543e+01, -2.5072e+01,\n",
            "         -2.3518e+01, -2.0263e+01, -1.8895e+01, -2.5254e+01, -1.9112e+01,\n",
            "         -2.7530e+01, -2.0101e+01, -3.2564e+01, -1.9780e+01, -2.6164e+01,\n",
            "         -1.8506e+01, -2.3502e+01, -2.3262e+01, -2.1848e+01, -2.8193e+01,\n",
            "         -2.6661e+01, -2.2556e+01, -2.4926e+01, -2.7202e+01, -2.6657e+01,\n",
            "         -2.4363e+01, -2.1728e+01, -1.7356e+01, -1.8788e+01, -2.6092e+01,\n",
            "         -2.8915e+01, -2.2940e+01, -2.4880e+01, -3.1834e+01, -2.6036e+01,\n",
            "         -2.0508e+01, -2.9321e+01, -2.8123e+01, -2.7390e+01, -3.2703e+01,\n",
            "         -2.5532e+01, -2.3776e+01]], device='cuda:0'), tensor([-0.0029], device='cuda:0'), tensor([9], device='cuda:0'), ['bn: Bengali'])\n",
            "tensor([0.9971], device='cuda:0')\n",
            "['bn: Bengali']\n"
          ]
        }
      ],
      "source": [
        "import torchaudio\n",
        "from speechbrain.inference.classifiers import EncoderClassifier\n",
        "import os\n",
        "# torchaudio.set_audio_backend(\"sox_io\")\n",
        "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
        "\n",
        "# Change the source to the directory containing hyperparams.yaml\n",
        "classifier = EncoderClassifier.from_hparams(\n",
        "    source=\"/content/\",\n",
        "    hparams_file=\"hyperparams.yaml\",\n",
        "    run_opts={\"device\": \"cuda:0\"}  # Changed to cuda:0\n",
        ")\n",
        "\n",
        "\n",
        "audio_path = \"/content/Sayani Ghosh Bengali.wav\"\n",
        "\n",
        "if not os.path.exists(audio_path):\n",
        "    raise FileNotFoundError(f\"File not found: {audio_path}\")\n",
        "\n",
        "\n",
        "signal = classifier.load_audio(audio_path)\n",
        "prediction = classifier.classify_batch(signal)\n",
        "\n",
        "print(prediction)\n",
        "print(prediction[1].exp())\n",
        "print(prediction[3])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchaudio\n",
        "from speechbrain.inference.classifiers import EncoderClassifier\n",
        "import os\n",
        "# torchaudio.set_audio_backend(\"sox_io\")\n",
        "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
        "\n",
        "# Change the source to the directory containing hyperparams.yaml\n",
        "classifier = EncoderClassifier.from_hparams(\n",
        "    source=\"/content/\",\n",
        "    hparams_file=\"hyperparams.yaml\",\n",
        "    run_opts={\"device\": \"cuda:0\"}  # Changed to cuda:0\n",
        ")\n",
        "\n",
        "\n",
        "audio_path = \"/content/Sudha Murty English.wav\"\n",
        "\n",
        "if not os.path.exists(audio_path):\n",
        "    raise FileNotFoundError(f\"File not found: {audio_path}\")\n",
        "\n",
        "\n",
        "signal = classifier.load_audio(audio_path)\n",
        "prediction = classifier.classify_batch(signal)\n",
        "\n",
        "print(prediction)\n",
        "print(prediction[1].exp())\n",
        "print(prediction[3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-aft9niYpdvS",
        "outputId": "3ecde363-570f-4716-c5c2-94edca2a4b30"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(tensor([[-12.2467,  -3.9077,  -7.4878,  -3.8609,  -7.2566, -10.1617,  -7.8436,\n",
            "          -9.5382,  -8.9792,  -7.2856, -11.3262, -10.6836,  -8.6989,  -7.2921,\n",
            "          -9.5089, -13.8012,  -5.1397,  -8.6077,  -8.0213,  -7.5331,  -6.0541,\n",
            "         -10.6342, -11.9700, -10.8149, -13.2298,  -8.9459,  -9.7703,  -5.7927,\n",
            "         -11.0792,  -8.7832, -15.5610,  -6.0382, -10.8671,  -6.1598,  -9.2993,\n",
            "          -1.0503,  -8.3590, -12.6897,  -8.4480,  -6.8315, -10.9436,  -8.3645,\n",
            "          -8.0487,  -9.9502,  -9.7200, -14.7816, -12.5785, -11.3673,  -9.7697,\n",
            "         -14.1414,  -3.7042, -10.6240, -11.3995,  -7.7551, -10.3771, -14.4184,\n",
            "          -9.0391,  -9.9566, -10.0598,  -8.6062,  -4.3148,  -3.1108,  -7.0956,\n",
            "          -3.7086,  -4.9748,  -3.5449, -14.6242,  -6.5242,  -7.4511,  -5.3633,\n",
            "          -7.2813,  -7.6801,  -3.5711,  -9.5607,  -3.8375,  -9.5320,  -6.4842,\n",
            "         -14.0627, -10.2554,  -5.7280,  -3.2570,  -8.4552, -13.0350,  -4.6312,\n",
            "          -6.4282,  -6.3844,  -7.4901,  -6.2907,  -9.9818,  -7.6730,  -6.4895,\n",
            "          -4.9159,  -1.4220,  -8.7424,  -9.7521,  -8.6347,  -4.8747,  -8.2301,\n",
            "         -10.0801, -10.5046,  -2.7313, -12.0714,  -9.1402,  -7.9259,  -9.7394,\n",
            "         -11.8389, -11.8586]], device='cuda:0'), tensor([-1.0503], device='cuda:0'), tensor([35], device='cuda:0'), ['hi: Hindi'])\n",
            "tensor([0.3498], device='cuda:0')\n",
            "['hi: Hindi']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchaudio\n",
        "from speechbrain.inference.classifiers import EncoderClassifier\n",
        "import os\n",
        "# torchaudio.set_audio_backend(\"sox_io\")\n",
        "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
        "\n",
        "# Change the source to the directory containing hyperparams.yaml\n",
        "classifier = EncoderClassifier.from_hparams(\n",
        "    source=\"/content/\",\n",
        "    hparams_file=\"hyperparams.yaml\",\n",
        "    run_opts={\"device\": \"cuda:0\"}  # Changed to cuda:0\n",
        ")\n",
        "\n",
        "\n",
        "audio_path = \"/content/Punjabi.wav\"\n",
        "\n",
        "if not os.path.exists(audio_path):\n",
        "    raise FileNotFoundError(f\"File not found: {audio_path}\")\n",
        "\n",
        "\n",
        "signal = classifier.load_audio(audio_path)\n",
        "prediction = classifier.classify_batch(signal)\n",
        "\n",
        "print(prediction)\n",
        "print(prediction[1].exp())\n",
        "print(prediction[3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cU_v2LOcpdxb",
        "outputId": "a3e5ee83-93f1-4bfb-8ade-3fbedde13be2"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(tensor([[-27.3148, -23.8845, -19.6518, -18.0312, -16.4431, -24.8118, -24.7435,\n",
            "         -25.7743, -28.0193, -17.5630, -21.8667, -28.5687, -23.6085, -19.8313,\n",
            "         -20.8006, -26.8281, -19.6168, -23.6418, -23.3828, -22.4028, -23.8812,\n",
            "         -23.0667, -27.0693, -25.3674, -24.9755, -21.6191, -23.8411, -25.1845,\n",
            "         -24.3548, -24.7537, -31.2314,  -8.6525, -27.9382, -22.2096, -21.0233,\n",
            "          -1.6791, -26.3546, -26.6237, -22.6808, -12.1557, -24.7824, -26.4318,\n",
            "         -22.4202, -26.1772, -20.4481, -27.8513, -27.4562, -21.2976, -26.6239,\n",
            "         -23.9387, -10.8846, -25.4061, -28.8563, -25.1358, -24.9674, -24.9666,\n",
            "         -28.8663, -24.6703, -24.9980, -23.3967, -19.5654, -14.0568, -22.4795,\n",
            "         -10.8681, -21.7795, -17.5549, -24.4232, -15.6051, -27.0431, -18.4874,\n",
            "         -20.8441, -22.0133,  -0.2812, -24.8321, -12.9344, -25.6489, -20.4809,\n",
            "         -30.9301, -11.3593, -16.0593,  -4.1864, -19.6829, -24.9659, -21.0669,\n",
            "         -26.9975, -22.1479, -20.3820, -23.1179, -22.2109, -19.7858, -23.7187,\n",
            "         -14.5787, -11.1102, -18.3952, -21.1372, -21.3660, -22.0128, -22.2020,\n",
            "         -26.9388, -25.6534,  -3.1440, -26.3267, -23.8455, -24.2241, -25.6214,\n",
            "         -25.7850, -22.7898]], device='cuda:0'), tensor([-0.2812], device='cuda:0'), tensor([72], device='cuda:0'), ['pa: Panjabi'])\n",
            "tensor([0.7549], device='cuda:0')\n",
            "['pa: Panjabi']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchaudio\n",
        "from speechbrain.inference.classifiers import EncoderClassifier\n",
        "import os\n",
        "# torchaudio.set_audio_backend(\"sox_io\")\n",
        "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
        "\n",
        "# Change the source to the directory containing hyperparams.yaml\n",
        "classifier = EncoderClassifier.from_hparams(\n",
        "    source=\"/content/\",\n",
        "    hparams_file=\"hyperparams.yaml\",\n",
        "    run_opts={\"device\": \"cuda:0\"}  # Changed to cuda:0\n",
        ")\n",
        "\n",
        "\n",
        "audio_path = \"/content/Tamil.wav\"\n",
        "\n",
        "if not os.path.exists(audio_path):\n",
        "    raise FileNotFoundError(f\"File not found: {audio_path}\")\n",
        "\n",
        "\n",
        "signal = classifier.load_audio(audio_path)\n",
        "prediction = classifier.classify_batch(signal)\n",
        "\n",
        "print(prediction)\n",
        "print(prediction[1].exp())\n",
        "print(prediction[3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dzmfUBdTIBI_",
        "outputId": "c131387d-8445-4be6-e376-6eed35ba0a8b"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(tensor([[-3.5366e+01, -2.1369e+01, -1.7227e+01, -2.4827e+01, -1.4586e+01,\n",
            "         -2.9319e+01, -3.1313e+01, -2.7192e+01, -2.7389e+01, -1.6335e+01,\n",
            "         -2.6579e+01, -2.8878e+01, -2.8719e+01, -1.9552e+01, -2.3208e+01,\n",
            "         -2.3613e+01, -2.1877e+01, -2.6793e+01, -2.6714e+01, -2.5992e+01,\n",
            "         -2.2331e+01, -2.9785e+01, -2.1337e+01, -2.4752e+01, -2.4295e+01,\n",
            "         -2.9575e+01, -2.6687e+01, -2.9471e+01, -2.8772e+01, -2.5046e+01,\n",
            "         -2.7686e+01, -1.7306e+01, -3.1682e+01, -2.2858e+01, -2.1909e+01,\n",
            "         -1.1975e+01, -2.6658e+01, -2.7165e+01, -2.7823e+01, -2.4250e+01,\n",
            "         -2.9039e+01, -1.9641e+01, -2.5252e+01, -2.5959e+01, -2.8131e+01,\n",
            "         -2.8512e+01, -1.8970e+01, -2.6578e+01, -2.6875e+01, -2.5049e+01,\n",
            "         -7.7275e+00, -2.1165e+01, -2.1425e+01, -2.8476e+01, -2.6836e+01,\n",
            "         -2.9353e+01, -2.6973e+01, -2.8474e+01, -2.4267e+01, -2.6443e+01,\n",
            "         -2.7589e+01, -6.3569e+00, -2.3885e+01, -1.2532e+01, -2.2031e+01,\n",
            "         -2.4794e+01, -2.5329e+01, -1.9147e+01, -2.6229e+01, -2.4907e+01,\n",
            "         -2.3413e+01, -2.5232e+01, -1.5688e+01, -2.7364e+01, -2.1015e+01,\n",
            "         -2.4095e+01, -1.8719e+01, -2.9683e+01, -1.6863e+01, -1.7885e+01,\n",
            "         -1.6299e+01, -9.3335e+00, -2.5395e+01, -2.3974e+01, -2.9102e+01,\n",
            "         -2.1013e+01, -2.8355e+01, -2.8772e+01, -2.1509e+01, -2.3983e+01,\n",
            "         -2.2478e+01, -3.1309e-03, -7.0688e+00, -3.1459e+01, -2.4193e+01,\n",
            "         -2.7141e+01, -2.0394e+01, -2.1882e+01, -2.6861e+01, -2.7661e+01,\n",
            "         -1.6694e+01, -2.6426e+01, -2.4027e+01, -2.2951e+01, -2.7440e+01,\n",
            "         -2.7425e+01, -2.6162e+01]], device='cuda:0'), tensor([-0.0031], device='cuda:0'), tensor([91], device='cuda:0'), ['ta: Tamil'])\n",
            "tensor([0.9969], device='cuda:0')\n",
            "['ta: Tamil']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchaudio\n",
        "from speechbrain.inference.classifiers import EncoderClassifier\n",
        "import os\n",
        "# torchaudio.set_audio_backend(\"sox_io\")\n",
        "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
        "\n",
        "# Change the source to the directory containing hyperparams.yaml\n",
        "classifier = EncoderClassifier.from_hparams(\n",
        "    source=\"/content/\",\n",
        "    hparams_file=\"hyperparams.yaml\",\n",
        "    run_opts={\"device\": \"cuda:0\"}  # Changed to cuda:0\n",
        ")\n",
        "\n",
        "\n",
        "audio_path = \"/content/Gujurati.wav\"\n",
        "\n",
        "if not os.path.exists(audio_path):\n",
        "    raise FileNotFoundError(f\"File not found: {audio_path}\")\n",
        "\n",
        "\n",
        "signal = classifier.load_audio(audio_path)\n",
        "prediction = classifier.classify_batch(signal)\n",
        "\n",
        "print(prediction)\n",
        "print(prediction[1].exp())\n",
        "print(prediction[3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aTIcigK0IBoF",
        "outputId": "2d064632-9fd0-4fc7-de28-4b7e5b333e28"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(tensor([[-21.4242, -13.9790, -14.0013, -12.5085, -12.6248, -22.9896, -17.7530,\n",
            "         -17.1227, -15.9427, -13.1963, -17.7214, -18.1771, -14.5632, -10.9548,\n",
            "         -13.9965, -18.4770, -18.7569, -19.6408, -19.4436, -14.3541, -18.5392,\n",
            "         -17.9366, -16.7948, -19.4782, -18.9892, -17.6394, -22.5440, -19.0168,\n",
            "         -17.6760, -18.5628, -22.0794,  -0.1716, -23.5776, -11.5298, -14.6788,\n",
            "          -2.1393, -18.0739, -17.2550, -20.0234, -12.9804, -20.1613, -14.0058,\n",
            "         -18.2765, -19.4510, -17.5061, -20.6278, -15.0249, -18.3528, -17.7624,\n",
            "         -15.3015,  -9.2064, -20.5530, -19.4792, -19.8507, -13.6337, -18.1789,\n",
            "         -18.6549, -20.4408, -14.7577, -20.8721, -11.4729, -14.4745, -17.2665,\n",
            "          -3.5015, -12.5691, -14.7138, -19.1441, -13.0861, -17.9956, -19.7032,\n",
            "         -19.2643, -14.2029,  -8.8719, -16.6406,  -9.6125, -17.8349, -12.9703,\n",
            "         -22.2400, -10.4364, -15.7752,  -4.7323, -12.7035, -16.6510, -12.3908,\n",
            "         -17.9066, -14.5344, -17.8908, -17.0876, -14.3930, -20.3925, -15.8500,\n",
            "         -13.3976,  -9.7339, -17.4391, -13.9736, -16.7535, -13.8356, -19.5615,\n",
            "         -18.9800, -17.6898,  -7.6397, -19.1610, -18.1932, -16.4513, -19.3022,\n",
            "         -16.7476, -18.2016]], device='cuda:0'), tensor([-0.1716], device='cuda:0'), tensor([31], device='cuda:0'), ['gu: Gujarati'])\n",
            "tensor([0.8424], device='cuda:0')\n",
            "['gu: Gujarati']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchaudio\n",
        "from speechbrain.inference.classifiers import EncoderClassifier\n",
        "import os\n",
        "# torchaudio.set_audio_backend(\"sox_io\")\n",
        "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
        "\n",
        "# Change the source to the directory containing hyperparams.yaml\n",
        "classifier = EncoderClassifier.from_hparams(\n",
        "    source=\"/content/\",\n",
        "    hparams_file=\"hyperparams.yaml\",\n",
        "    run_opts={\"device\": \"cuda:0\"}  # Changed to cuda:0\n",
        ")\n",
        "\n",
        "\n",
        "audio_path = \"/content/Telugu.wav\"\n",
        "\n",
        "if not os.path.exists(audio_path):\n",
        "    raise FileNotFoundError(f\"File not found: {audio_path}\")\n",
        "\n",
        "\n",
        "signal = classifier.load_audio(audio_path)\n",
        "prediction = classifier.classify_batch(signal)\n",
        "\n",
        "print(prediction)\n",
        "print(prediction[1].exp())\n",
        "print(prediction[3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UnLaU5S6IBvU",
        "outputId": "bf47b96a-5bcc-438a-ccf0-bcf35b17fa7b"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(tensor([[-22.9878, -15.2069,  -9.8938, -10.4453,  -8.5811, -18.6481, -11.3497,\n",
            "         -13.4263, -14.6886, -10.2410, -14.4296, -18.3593, -11.3153, -11.9840,\n",
            "         -13.8621, -15.1595, -18.2111, -16.8179, -17.2613,  -8.1977, -15.8590,\n",
            "         -18.7139, -14.8401, -18.9520, -16.0306, -17.8045, -14.4275, -19.1396,\n",
            "         -17.4278, -12.9963, -17.5289,  -6.0711, -22.2126, -11.2234, -15.7740,\n",
            "          -4.1817, -11.6828, -14.5721, -14.6705, -15.3308, -18.5367, -16.1911,\n",
            "         -14.0460, -13.4053, -14.4340, -12.5940, -14.0822, -15.3139, -12.1449,\n",
            "         -21.4039,  -0.7935, -16.3003, -20.6341, -18.5174, -13.2415, -16.6803,\n",
            "         -14.6211, -17.0358, -16.3971, -17.8870,  -8.8133,  -6.7945, -15.8481,\n",
            "          -5.5971, -11.0946, -14.0577, -17.0333, -13.1530, -19.7460, -21.6040,\n",
            "         -20.5024, -17.2443,  -9.0492, -11.6963,  -4.3769, -17.1159, -10.9780,\n",
            "         -14.5553, -13.6017, -15.9792,  -5.4648,  -7.6595, -17.1496, -10.7930,\n",
            "         -18.0934, -12.1389, -12.7314, -13.2043, -15.8883, -18.6883, -12.1108,\n",
            "          -3.4503,  -0.7441, -14.9530, -14.3473, -12.5946, -11.8975, -15.6877,\n",
            "         -15.9649, -14.7087,  -8.8989, -17.9314, -17.7257, -13.8027, -19.0934,\n",
            "         -14.9810, -20.4248]], device='cuda:0'), tensor([-0.7441], device='cuda:0'), tensor([92], device='cuda:0'), ['te: Telugu'])\n",
            "tensor([0.4752], device='cuda:0')\n",
            "['te: Telugu']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchaudio\n",
        "from speechbrain.inference.classifiers import EncoderClassifier\n",
        "import os\n",
        "# torchaudio.set_audio_backend(\"sox_io\")\n",
        "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
        "\n",
        "# Change the source to the directory containing hyperparams.yaml\n",
        "classifier = EncoderClassifier.from_hparams(\n",
        "    source=\"/content/\",\n",
        "    hparams_file=\"hyperparams.yaml\",\n",
        "    run_opts={\"device\": \"cuda:0\"}  # Changed to cuda:0\n",
        ")\n",
        "\n",
        "\n",
        "audio_path = \"/content/Marathi.wav\"\n",
        "\n",
        "if not os.path.exists(audio_path):\n",
        "    raise FileNotFoundError(f\"File not found: {audio_path}\")\n",
        "\n",
        "\n",
        "signal = classifier.load_audio(audio_path)\n",
        "prediction = classifier.classify_batch(signal)\n",
        "\n",
        "print(prediction)\n",
        "print(prediction[1].exp())\n",
        "print(prediction[3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Zb6bHHpUPco",
        "outputId": "ac3d1cd6-90e3-449b-9572-416a1e680d9b"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(tensor([[-21.1757, -13.8872, -13.8583, -10.5370,  -9.0707, -17.2636, -17.6157,\n",
            "         -18.3194, -16.6353, -11.3035, -17.0193, -17.9981, -16.9382, -11.1743,\n",
            "         -20.5130, -17.4338, -17.5707, -16.7094, -19.4866, -12.1118, -14.2781,\n",
            "         -17.8332, -14.9716, -17.3388, -16.5691, -15.7920, -19.9277, -16.9722,\n",
            "         -13.3260, -15.5844, -20.6016,  -4.8034, -24.8886, -13.3427, -17.8578,\n",
            "          -1.5135, -16.9093, -19.1766, -15.7550, -10.9727, -24.1737, -15.3048,\n",
            "         -16.1370, -16.7920, -16.6707, -14.4717, -16.8941, -15.8112, -17.3805,\n",
            "         -16.9509,  -8.0503, -15.1691, -18.7809, -15.8769, -13.7911, -18.1174,\n",
            "         -17.1223, -18.7983, -18.4651, -21.2981, -15.2197,  -9.2162, -16.1868,\n",
            "          -0.2658, -13.8805, -10.8662, -16.7348, -13.9934, -19.3703, -16.7174,\n",
            "         -16.2040, -13.1827,  -7.4918, -16.0577, -10.7445, -15.7174, -11.8977,\n",
            "         -22.2081,  -9.2085, -21.0096,  -6.1040, -11.1553, -17.7142, -12.3263,\n",
            "         -20.1392, -17.5367, -14.6628, -15.3336, -14.1413, -15.0664, -11.7908,\n",
            "         -10.7812, -10.0466, -12.7856, -16.0215, -15.1469, -14.1049, -15.1175,\n",
            "         -19.0088, -16.0677,  -6.5670, -16.7242, -12.8863, -15.7624, -20.9295,\n",
            "         -16.2467, -15.6100]], device='cuda:0'), tensor([-0.2658], device='cuda:0'), tensor([63], device='cuda:0'), ['mr: Marathi'])\n",
            "tensor([0.7666], device='cuda:0')\n",
            "['mr: Marathi']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchaudio\n",
        "from speechbrain.inference.classifiers import EncoderClassifier\n",
        "import os\n",
        "# torchaudio.set_audio_backend(\"sox_io\")\n",
        "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
        "\n",
        "# Change the source to the directory containing hyperparams.yaml\n",
        "classifier = EncoderClassifier.from_hparams(\n",
        "    source=\"/content/\",\n",
        "    hparams_file=\"hyperparams.yaml\",\n",
        "    run_opts={\"device\": \"cuda:0\"}  # Changed to cuda:0\n",
        ")\n",
        "\n",
        "\n",
        "audio_path = \"/content/French.wav\"\n",
        "\n",
        "if not os.path.exists(audio_path):\n",
        "    raise FileNotFoundError(f\"File not found: {audio_path}\")\n",
        "\n",
        "\n",
        "signal = classifier.load_audio(audio_path)\n",
        "prediction = classifier.classify_batch(signal)\n",
        "\n",
        "print(prediction)\n",
        "print(prediction[1].exp())\n",
        "print(prediction[3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xyFOiNFSUYBi",
        "outputId": "7367bfed-a921-4310-bba5-3f41fb8af242"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(tensor([[-10.8627,  -9.8119,  -9.6040, -10.0181,  -6.6038,  -2.0602, -10.8816,\n",
            "          -8.3746,  -8.9410,  -7.1394,  -6.7198,  -8.8754,  -9.5948,  -8.2151,\n",
            "         -11.0126,  -6.7327, -11.1514,  -9.7260,  -8.4554,  -6.2228,  -5.0956,\n",
            "          -6.9600,  -7.2739,  -8.8841,  -8.8215,  -3.4635,  -9.3441,  -2.0675,\n",
            "          -4.9519, -11.8042, -10.3657,  -6.4364,  -4.6356,  -9.0869,  -7.2703,\n",
            "          -6.6285, -11.0741,  -2.8320,  -8.2831,  -7.4016,  -9.5247,  -9.2536,\n",
            "         -10.5973,  -8.1337, -10.6132,  -8.7735,  -8.3872,  -7.7170,  -6.1702,\n",
            "         -13.2582,  -7.3064,  -8.4767,  -8.4783,  -7.3006,  -3.1536, -14.2126,\n",
            "         -10.2820, -13.6927,  -5.5197,  -9.8282,  -6.1733,  -7.6939,  -7.9631,\n",
            "          -9.4813,  -5.3856, -15.8328,  -9.7093, -11.8308,  -5.9515,  -4.2476,\n",
            "          -5.5339,  -9.3872, -10.5903,  -3.9020,  -9.7142,  -5.7210,  -6.6274,\n",
            "         -12.6174,  -8.1599, -10.4421,  -7.7664, -12.5376,  -1.7607,  -7.5397,\n",
            "          -6.4727,  -8.8703,  -3.3585,  -8.2518, -10.2528,  -2.7333,  -7.8475,\n",
            "          -8.5191,  -5.7782,  -7.2160, -11.4611, -12.1383,  -8.3615,  -4.9031,\n",
            "          -8.9165,  -8.6377, -13.5925,  -5.7529,  -9.5057, -13.0745, -10.5015,\n",
            "          -1.5388,  -4.8681]], device='cuda:0'), tensor([-1.5388], device='cuda:0'), tensor([105], device='cuda:0'), ['yo: Yoruba'])\n",
            "tensor([0.2146], device='cuda:0')\n",
            "['yo: Yoruba']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchaudio\n",
        "from speechbrain.inference.classifiers import EncoderClassifier\n",
        "import os\n",
        "# torchaudio.set_audio_backend(\"sox_io\")\n",
        "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
        "\n",
        "# Change the source to the directory containing hyperparams.yaml\n",
        "classifier = EncoderClassifier.from_hparams(\n",
        "    source=\"/content/\",\n",
        "    hparams_file=\"hyperparams.yaml\",\n",
        "    run_opts={\"device\": \"cuda:0\"}  # Changed to cuda:0\n",
        ")\n",
        "\n",
        "\n",
        "audio_path = \"/content/French.wav\"\n",
        "\n",
        "if not os.path.exists(audio_path):\n",
        "    raise FileNotFoundError(f\"File not found: {audio_path}\")\n",
        "\n",
        "\n",
        "signal = classifier.load_audio(audio_path)\n",
        "prediction = classifier.classify_batch(signal)\n",
        "\n",
        "print(prediction)\n",
        "print(prediction[1].exp())\n",
        "print(prediction[3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rDYmHKFIUYJ4",
        "outputId": "b50388dc-a558-46f3-9972-c27febd2ed2e"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(tensor([[-2.0024e+01, -1.7835e+01, -1.8596e+01, -1.0728e+01, -1.7604e+01,\n",
            "         -1.8128e+01, -1.9697e+01, -1.5110e+01, -1.6630e+01, -1.8990e+01,\n",
            "         -2.0353e+01, -6.5291e+00, -1.9740e+01, -1.3757e+01, -1.8656e+01,\n",
            "         -1.4363e+01, -1.3049e+01, -1.2641e+01, -1.6052e+01, -1.2347e+01,\n",
            "         -1.4738e+01, -1.4626e+01, -1.6341e+01, -1.5920e+01, -1.8828e+01,\n",
            "         -1.7313e+01, -1.7489e+01, -1.3185e+01, -2.4189e-03, -1.5560e+01,\n",
            "         -2.0597e+01, -2.2815e+01, -1.6762e+01, -1.5356e+01, -2.2226e+01,\n",
            "         -1.6596e+01, -1.9696e+01, -1.3200e+01, -1.7153e+01, -1.6257e+01,\n",
            "         -2.0826e+01, -1.7143e+01, -1.7312e+01, -1.8476e+01, -1.5399e+01,\n",
            "         -1.5940e+01, -1.8539e+01, -2.0363e+01, -1.8187e+01, -2.0098e+01,\n",
            "         -2.2053e+01, -1.7083e+01, -1.3348e+01, -9.6430e+00, -9.7846e+00,\n",
            "         -2.3275e+01, -1.4033e+01, -2.1117e+01, -1.4215e+01, -1.8671e+01,\n",
            "         -1.6658e+01, -2.3165e+01, -2.0970e+01, -2.0873e+01, -1.7785e+01,\n",
            "         -1.1570e+01, -2.3535e+01, -2.4412e+01, -1.1679e+01, -1.1070e+01,\n",
            "         -1.0198e+01, -7.2893e+00, -2.1256e+01, -1.2349e+01, -1.5277e+01,\n",
            "         -1.0897e+01, -1.4339e+01, -1.7301e+01, -2.0785e+01, -2.1995e+01,\n",
            "         -1.9089e+01, -2.3374e+01, -1.4991e+01, -1.5034e+01, -1.6361e+01,\n",
            "         -2.0423e+01, -1.5122e+01, -1.7178e+01, -2.1368e+01, -1.1331e+01,\n",
            "         -1.4675e+01, -2.3483e+01, -2.1248e+01, -1.8054e+01, -1.9561e+01,\n",
            "         -1.9228e+01, -1.7577e+01, -1.7918e+01, -1.8610e+01, -1.4573e+01,\n",
            "         -1.6447e+01, -1.6437e+01, -1.8135e+01, -1.8993e+01, -1.8615e+01,\n",
            "         -1.7396e+01, -1.4758e+01]], device='cuda:0'), tensor([-0.0024], device='cuda:0'), tensor([28], device='cuda:0'), ['fr: French'])\n",
            "tensor([0.9976], device='cuda:0')\n",
            "['fr: French']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchaudio\n",
        "from speechbrain.inference.classifiers import EncoderClassifier\n",
        "import os\n",
        "# torchaudio.set_audio_backend(\"sox_io\")\n",
        "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
        "\n",
        "# Change the source to the directory containing hyperparams.yaml\n",
        "classifier = EncoderClassifier.from_hparams(\n",
        "    source=\"/content/\",\n",
        "    hparams_file=\"hyperparams.yaml\",\n",
        "    run_opts={\"device\": \"cuda:0\"}  # Changed to cuda:0\n",
        ")\n",
        "\n",
        "\n",
        "audio_path = \"/content/Arabic.wav\"\n",
        "\n",
        "if not os.path.exists(audio_path):\n",
        "    raise FileNotFoundError(f\"File not found: {audio_path}\")\n",
        "\n",
        "\n",
        "signal = classifier.load_audio(audio_path)\n",
        "prediction = classifier.classify_batch(signal)\n",
        "\n",
        "print(prediction)\n",
        "print(prediction[1].exp())\n",
        "print(prediction[3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v3hTnDDCXUjp",
        "outputId": "515d6d22-92b5-4161-e8b0-ded8978ee6a9"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(tensor([[-1.6470e+01, -1.7433e+01, -7.4484e+00, -1.0241e-02, -1.6380e+01,\n",
            "         -1.3923e+01, -1.2126e+01, -1.5590e+01, -1.7882e+01, -9.8756e+00,\n",
            "         -1.7941e+01, -1.8131e+01, -1.0188e+01, -1.5671e+01, -1.8281e+01,\n",
            "         -1.9543e+01, -1.5441e+01, -1.3736e+01, -1.4894e+01, -1.3723e+01,\n",
            "         -1.7686e+01, -1.8414e+01, -1.4328e+01, -1.8792e+01, -1.6516e+01,\n",
            "         -9.5875e+00, -1.5842e+01, -1.2686e+01, -1.5154e+01, -1.5164e+01,\n",
            "         -2.0282e+01, -1.6072e+01, -1.8731e+01, -6.4608e+00, -1.6100e+01,\n",
            "         -1.1547e+01, -1.7598e+01, -1.9512e+01, -1.4661e+01, -1.4960e+01,\n",
            "         -1.6892e+01, -1.7397e+01, -1.4761e+01, -1.5396e+01, -1.1044e+01,\n",
            "         -1.7054e+01, -1.6064e+01, -1.8064e+01, -1.2231e+01, -1.7570e+01,\n",
            "         -1.1155e+01, -1.7905e+01, -2.3494e+01, -1.7836e+01, -1.8991e+01,\n",
            "         -1.6971e+01, -1.5622e+01, -1.7733e+01, -1.8241e+01, -2.0138e+01,\n",
            "         -1.2897e+01, -9.4338e+00, -1.7605e+01, -1.4759e+01, -1.0349e+01,\n",
            "         -6.3593e+00, -1.7102e+01, -1.6421e+01, -1.5607e+01, -1.0678e+01,\n",
            "         -1.2800e+01, -1.4529e+01, -1.7117e+01, -1.7531e+01, -6.9364e+00,\n",
            "         -1.7334e+01, -1.3388e+01, -1.8666e+01, -1.3242e+01, -1.9004e+01,\n",
            "         -8.5105e+00, -1.5187e+01, -1.7785e+01, -1.3476e+01, -2.0036e+01,\n",
            "         -5.4503e+00, -1.5896e+01, -1.4865e+01, -1.3572e+01, -1.2830e+01,\n",
            "         -1.7416e+01, -1.3990e+01, -1.2578e+01, -7.8805e+00, -1.3715e+01,\n",
            "         -1.3765e+01, -1.0413e+01, -1.2338e+01, -1.1952e+01, -1.4887e+01,\n",
            "         -1.0074e+01, -1.2919e+01, -1.3409e+01, -1.4443e+01, -1.3585e+01,\n",
            "         -1.5567e+01, -1.7941e+01]], device='cuda:0'), tensor([-0.0102], device='cuda:0'), tensor([3], device='cuda:0'), ['ar: Arabic'])\n",
            "tensor([0.9898], device='cuda:0')\n",
            "['ar: Arabic']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchaudio\n",
        "from speechbrain.inference.classifiers import EncoderClassifier\n",
        "import os\n",
        "# torchaudio.set_audio_backend(\"sox_io\")\n",
        "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
        "\n",
        "# Change the source to the directory containing hyperparams.yaml\n",
        "classifier = EncoderClassifier.from_hparams(\n",
        "    source=\"/content/\",\n",
        "    hparams_file=\"hyperparams.yaml\",\n",
        "    run_opts={\"device\": \"cuda:0\"}  # Changed to cuda:0\n",
        ")\n",
        "\n",
        "\n",
        "audio_path = \"/content/Tibetan.wav\"\n",
        "\n",
        "if not os.path.exists(audio_path):\n",
        "    raise FileNotFoundError(f\"File not found: {audio_path}\")\n",
        "\n",
        "\n",
        "signal = classifier.load_audio(audio_path)\n",
        "prediction = classifier.classify_batch(signal)\n",
        "\n",
        "print(prediction)\n",
        "print(prediction[1].exp())\n",
        "print(prediction[3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eLhBU3RgXeBV",
        "outputId": "d7bedb81-cf1e-4e4d-a786-847fbcf29215"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(tensor([[-14.8948, -17.9096, -14.0768, -11.9924,  -7.5222,  -8.6214, -16.7444,\n",
            "         -14.7388, -15.7302,  -8.9541,  -0.3925, -14.9657, -13.6783, -16.2974,\n",
            "         -13.4472, -17.0240, -10.8722,  -9.4914, -11.9939, -11.0720,  -8.8322,\n",
            "         -10.1525, -15.0398, -12.8695, -17.8728,  -8.8429, -12.1554, -11.3322,\n",
            "          -9.8458, -17.3760, -17.7311, -12.5920, -10.7497,  -7.8599, -13.7835,\n",
            "          -6.0500, -15.9578, -12.2855, -11.9651,  -9.4562, -17.5583, -16.4223,\n",
            "         -12.9821, -15.1422, -13.9128,  -8.4730, -17.2929, -14.0434, -12.8290,\n",
            "         -12.2412,  -9.2998,  -4.2993, -13.2596,  -8.4933, -16.8833, -12.3996,\n",
            "         -14.6142, -18.2877, -11.9495, -14.2613, -13.3876, -10.2177, -12.9006,\n",
            "         -10.8328, -12.6277, -11.6073, -11.3584, -14.2944, -14.5414,  -9.0185,\n",
            "         -10.5286, -10.0116, -12.7475, -11.6161, -11.2268, -10.8871, -12.2970,\n",
            "         -17.5131, -10.1542, -12.1435, -10.9835, -11.0123, -13.7411, -13.4284,\n",
            "         -12.6326, -17.9761, -15.7964, -11.6885, -18.6846, -10.3889, -12.2742,\n",
            "          -8.1817,  -9.0843, -11.4721,  -6.9767, -17.4849, -13.5215,  -7.6034,\n",
            "         -15.4896, -17.2824,  -8.5622,  -9.9881,  -7.3903, -14.1551, -16.5832,\n",
            "         -15.6845,  -1.1935]], device='cuda:0'), tensor([-0.3925], device='cuda:0'), tensor([10], device='cuda:0'), ['bo: Tibetan'])\n",
            "tensor([0.6753], device='cuda:0')\n",
            "['bo: Tibetan']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchaudio\n",
        "from speechbrain.inference.classifiers import EncoderClassifier\n",
        "import os\n",
        "# torchaudio.set_audio_backend(\"sox_io\")\n",
        "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
        "\n",
        "# Change the source to the directory containing hyperparams.yaml\n",
        "classifier = EncoderClassifier.from_hparams(\n",
        "    source=\"/content/\",\n",
        "    hparams_file=\"hyperparams.yaml\",\n",
        "    run_opts={\"device\": \"cuda:0\"}  # Changed to cuda:0\n",
        ")\n",
        "\n",
        "\n",
        "audio_path = \"/content/Assamese.wav\"\n",
        "\n",
        "if not os.path.exists(audio_path):\n",
        "    raise FileNotFoundError(f\"File not found: {audio_path}\")\n",
        "\n",
        "\n",
        "signal = classifier.load_audio(audio_path)\n",
        "prediction = classifier.classify_batch(signal)\n",
        "\n",
        "print(prediction)\n",
        "print(prediction[1].exp())\n",
        "print(prediction[3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HSE6mQbGXeJO",
        "outputId": "2fb90ef7-aeec-4f81-c731-d448997e9ffe"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(tensor([[-2.3388e+01, -1.2274e+01, -1.6876e+01, -1.4249e+01, -9.2821e-03,\n",
            "         -1.9357e+01, -2.1150e+01, -1.7942e+01, -1.8138e+01, -4.8854e+00,\n",
            "         -1.8525e+01, -1.8887e+01, -1.8007e+01, -1.5080e+01, -1.3240e+01,\n",
            "         -1.8265e+01, -1.2026e+01, -1.1137e+01, -1.5459e+01, -8.9058e+00,\n",
            "         -1.1002e+01, -1.8620e+01, -1.3891e+01, -1.2020e+01, -1.6927e+01,\n",
            "         -1.2769e+01, -1.4409e+01, -1.4704e+01, -1.6592e+01, -1.4935e+01,\n",
            "         -2.1165e+01, -1.2996e+01, -1.7363e+01, -1.2800e+01, -1.4689e+01,\n",
            "         -9.3600e+00, -1.6701e+01, -1.3214e+01, -1.7116e+01, -1.5238e+01,\n",
            "         -2.0569e+01, -1.1687e+01, -1.2748e+01, -1.4011e+01, -1.4327e+01,\n",
            "         -1.6471e+01, -1.4669e+01, -1.7058e+01, -2.1219e+01, -1.9643e+01,\n",
            "         -1.0378e+01, -1.2966e+01, -1.9023e+01, -1.6794e+01, -1.4192e+01,\n",
            "         -1.9257e+01, -1.8090e+01, -1.9074e+01, -1.6363e+01, -1.8896e+01,\n",
            "         -1.1821e+01, -1.0030e+01, -1.6883e+01, -9.7973e+00, -9.9372e+00,\n",
            "         -1.3236e+01, -1.7426e+01, -1.1809e+01, -1.5224e+01, -1.3526e+01,\n",
            "         -1.3333e+01, -1.5724e+01, -1.3910e+01, -1.8414e+01, -1.7270e+01,\n",
            "         -1.2119e+01, -1.2833e+01, -2.1832e+01, -1.6237e+01, -9.8001e+00,\n",
            "         -1.3064e+01, -1.2990e+01, -2.0047e+01, -1.4613e+01, -1.2365e+01,\n",
            "         -1.5207e+01, -1.7638e+01, -1.5113e+01, -1.4055e+01, -1.1576e+01,\n",
            "         -1.0724e+01, -1.2174e+01, -6.8768e+00, -1.6429e+01, -1.1903e+01,\n",
            "         -2.1088e+01, -1.2559e+01, -1.6673e+01, -2.2546e+01, -1.9866e+01,\n",
            "         -1.0922e+01, -1.8776e+01, -1.5927e+01, -1.5744e+01, -1.8359e+01,\n",
            "         -1.1483e+01, -1.5519e+01]], device='cuda:0'), tensor([-0.0093], device='cuda:0'), tensor([4], device='cuda:0'), ['as: Assamese'])\n",
            "tensor([0.9908], device='cuda:0')\n",
            "['as: Assamese']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bmRnEOtnXePo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OGW09lsbXeTv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LjV42R3fXeWZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GL3kac3fXeZA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_wd1SVe8Xec0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pMWhlIxQXefn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}